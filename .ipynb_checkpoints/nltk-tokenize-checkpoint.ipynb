{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nltk (Natural Languate Toolkit): https://www.nltk.org/\n",
    "- dummy text generator: https://www.blindtextgenerator.com/lorem-ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jkpark/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Far far away, behind the word mountains, far f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Separated they live in Bookmarksgrove right at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A small river named Duden flows by their place...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is a paradisematic country, in which roaste...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Even the all-powerful Pointing has no control ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Big Oxmox advised her not to do so, becaus...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>She packed her seven versalia, put her initial...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When she reached the first hills of the Italic...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pityful a rethoric question ran over her cheek...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Far far away, behind the word mountains, far f...       0\n",
       "1  Separated they live in Bookmarksgrove right at...       1\n",
       "2  A small river named Duden flows by their place...       2\n",
       "3  It is a paradisematic country, in which roaste...       3\n",
       "4  Even the all-powerful Pointing has no control ...       4\n",
       "5  The Big Oxmox advised her not to do so, becaus...       5\n",
       "6  She packed her seven versalia, put her initial...       6\n",
       "7  When she reached the first hills of the Italic...       7\n",
       "8  Pityful a rethoric question ran over her cheek...       8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = \"\"\"Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts.\n",
    "\n",
    "Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.\n",
    "\n",
    "A small river named Duden flows by their place and supplies it with the necessary regelialia.\n",
    "\n",
    "It is a paradisematic country, in which roasted parts of sentences fly into your mouth.\n",
    "\n",
    "Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.\n",
    "\n",
    "The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn’t listen.\n",
    "\n",
    "She packed her seven versalia, put her initial into the belt and made herself on the way.\n",
    "\n",
    "When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane.\n",
    "\n",
    "Pityful a rethoric question ran over her cheek, then\"\"\"\n",
    "\n",
    "doc_list = documents.split(\"\\n\\n\")\n",
    "df = pd.DataFrame(data=zip(doc_list, range(9)), columns=[\"text\", \"target\"])\n",
    "arr = np.array(df['text'])\n",
    "\n",
    "print(arr.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223 \n",
      " ['Far', 'far', 'away', ',', 'behind', 'the', 'word', 'mountains', ',', 'far', 'from', 'the', 'countries', 'Vokalia', 'and', 'Consonantia', ',', 'there', 'live', 'the', 'blind', 'texts', '.', 'Separated', 'they', 'live', 'in', 'Bookmarksgrove', 'right', 'at', 'the', 'coast', 'of', 'the', 'Semantics', ',', 'a', 'large', 'language', 'ocean', '.', 'A', 'small', 'river', 'named', 'Duden', 'flows', 'by', 'their', 'place'] \n",
      "\n",
      "223 \n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2] \n",
      "\n",
      "147 \n",
      " {'Far': 1, 'far': 3, 'away': 1, ',': 13, 'behind': 1, 'the': 19, 'word': 1, 'mountains': 1, 'from': 1, 'countries': 1, 'Vokalia': 1, 'and': 5, 'Consonantia': 1, 'there': 2, 'live': 2, 'blind': 3, 'texts': 2, '.': 8, 'Separated': 1, 'they': 1, 'in': 2, 'Bookmarksgrove': 2, 'right': 1, 'at': 1, 'coast': 1, 'of': 10, 'Semantics': 1, 'a': 5, 'large': 1, 'language': 1, 'ocean': 1, 'A': 1, 'small': 2, 'river': 1, 'named': 1, 'Duden': 1, 'flows': 1, 'by': 2, 'their': 1, 'place': 1, 'supplies': 1, 'it': 2, 'with': 1, 'necessary': 1, 'regelialia': 1, 'It': 1, 'is': 2, 'paradisematic': 1, 'country': 1, 'which': 1, 'roasted': 1, 'parts': 1, 'sentences': 1, 'fly': 1, 'into': 2, 'your': 1, 'mouth': 1, 'Even': 1, 'all-powerful': 1, 'Pointing': 1, 'has': 1, 'no': 1, 'control': 1, 'about': 1, 'an': 1, 'almost': 1, 'unorthographic': 1, 'life': 1, 'One': 1, 'day': 1, 'however': 1, 'line': 1, 'text': 1, 'name': 1, 'Lorem': 1, 'Ipsum': 1, 'decided': 1, 'to': 2, 'leave': 1, 'for': 1, 'World': 1, 'Grammar': 1, 'The': 1, 'Big': 1, 'Oxmox': 1, 'advised': 1, 'her': 6, 'not': 1, 'do': 1, 'so': 1, 'because': 1, 'were': 1, 'thousands': 1, 'bad': 1, 'Commas': 1, 'wild': 1, 'Question': 1, 'Marks': 1, 'devious': 1, 'Semikoli': 1, 'but': 1, 'Little': 1, 'Blind': 1, 'Text': 1, 'didn': 1, '’': 1, 't': 1, 'listen': 1, 'She': 1, 'packed': 1, 'seven': 1, 'versalia': 1, 'put': 1, 'initial': 1, 'belt': 1, 'made': 1, 'herself': 1, 'on': 2, 'way': 1, 'When': 1, 'she': 2, 'reached': 1, 'first': 1, 'hills': 1, 'Italic': 1, 'Mountains': 1, 'had': 1, 'last': 1, 'view': 1, 'back': 1, 'skyline': 1, 'hometown': 1, 'headline': 1, 'Alphabet': 1, 'Village': 1, 'subline': 1, 'own': 1, 'road': 1, 'Line': 1, 'Lane': 1, 'Pityful': 1, 'rethoric': 1, 'question': 1, 'ran': 1, 'over': 1, 'cheek': 1, 'then': 1}\n"
     ]
    }
   ],
   "source": [
    "# make linearized tokens and stretched targets\n",
    "\n",
    "tokens = []\n",
    "targets = []\n",
    "for doc, tgt in zip(arr, df['target']):\n",
    "    token = word_tokenize(doc)\n",
    "    tokens += token\n",
    "    \n",
    "    for _ in range(len(token)):\n",
    "        targets.append(tgt)\n",
    "        \n",
    "print(len(tokens), \"\\n\", tokens[:50], \"\\n\")\n",
    "print(len(targets), \"\\n\", targets[:50], \"\\n\")\n",
    "\n",
    "# counts\n",
    "counts = Counter(tokens)\n",
    "print(len(counts), \"\\n\", dict(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of stopwords:  183 \n",
      "\n",
      "114 \n",
      " ['Far', 'far', 'away', 'behind', 'word', 'mountains', 'far', 'countries', 'Vokalia', 'Consonantia', 'live', 'blind', 'texts', 'Separated', 'live', 'Bookmarksgrove', 'right', 'coast', 'Semantics', 'large', 'language', 'ocean', 'A', 'small', 'river', 'named', 'Duden', 'flows', 'place', 'supplies', 'necessary', 'regelialia', 'It', 'paradisematic', 'country', 'roasted', 'parts', 'sentences', 'fly', 'mouth', 'Even', 'all-powerful', 'Pointing', 'control', 'blind', 'texts', 'almost', 'unorthographic', 'life', 'One'] \n",
      "\n",
      "114 \n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
      "\n",
      "106 \n",
      " {'Far': 1, 'far': 3, 'away': 1, 'behind': 1, 'word': 1, 'mountains': 1, 'countries': 1, 'Vokalia': 1, 'Consonantia': 1, 'live': 2, 'blind': 3, 'texts': 2, 'Separated': 1, 'Bookmarksgrove': 2, 'right': 1, 'coast': 1, 'Semantics': 1, 'large': 1, 'language': 1, 'ocean': 1, 'A': 1, 'small': 2, 'river': 1, 'named': 1, 'Duden': 1, 'flows': 1, 'place': 1, 'supplies': 1, 'necessary': 1, 'regelialia': 1, 'It': 1, 'paradisematic': 1, 'country': 1, 'roasted': 1, 'parts': 1, 'sentences': 1, 'fly': 1, 'mouth': 1, 'Even': 1, 'all-powerful': 1, 'Pointing': 1, 'control': 1, 'almost': 1, 'unorthographic': 1, 'life': 1, 'One': 1, 'day': 1, 'however': 1, 'line': 1, 'text': 1, 'name': 1, 'Lorem': 1, 'Ipsum': 1, 'decided': 1, 'leave': 1, 'World': 1, 'Grammar': 1, 'The': 1, 'Big': 1, 'Oxmox': 1, 'advised': 1, 'thousands': 1, 'bad': 1, 'Commas': 1, 'wild': 1, 'Question': 1, 'Marks': 1, 'devious': 1, 'Semikoli': 1, 'Little': 1, 'Blind': 1, 'Text': 1, '’': 1, 'listen': 1, 'She': 1, 'packed': 1, 'seven': 1, 'versalia': 1, 'put': 1, 'initial': 1, 'belt': 1, 'made': 1, 'way': 1, 'When': 1, 'reached': 1, 'first': 1, 'hills': 1, 'Italic': 1, 'Mountains': 1, 'last': 1, 'view': 1, 'back': 1, 'skyline': 1, 'hometown': 1, 'headline': 1, 'Alphabet': 1, 'Village': 1, 'subline': 1, 'road': 1, 'Line': 1, 'Lane': 1, 'Pityful': 1, 'rethoric': 1, 'question': 1, 'ran': 1, 'cheek': 1}\n"
     ]
    }
   ],
   "source": [
    "# apply stopwords\n",
    "\n",
    "eng_stopwords = set(stopwords.words('english') + [\".\", \",\", \"?\", \"!\"])\n",
    "print(\"lenth of stopwords: \", len(eng_stopwords), \"\\n\")\n",
    "\n",
    "tokens = []\n",
    "targets = []\n",
    "for doc, tgt in zip(arr, df['target']):\n",
    "    token = word_tokenize(doc)\n",
    "    token = [tk for tk in token if tk not in eng_stopwords]\n",
    "    for _ in range(len(token)):\n",
    "        targets.append(tgt)\n",
    "    tokens += token\n",
    "    \n",
    "print(len(tokens), \"\\n\", tokens[:50], \"\\n\")\n",
    "print(len(targets), \"\\n\", targets[:50], \"\\n\")\n",
    "\n",
    "# counts\n",
    "counts = Counter(tokens)\n",
    "print(len(counts), \"\\n\", dict(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of stopwords:  183 \n",
      "\n",
      "109 \n",
      " ['far', 'far', 'away', 'behind', 'word', 'mountains', 'far', 'countries', 'vokalia', 'consonantia', 'live', 'blind', 'texts', 'separated', 'live', 'bookmarksgrove', 'right', 'coast', 'semantics', 'large', 'language', 'ocean', 'small', 'river', 'named', 'duden', 'flows', 'place', 'supplies', 'necessary', 'regelialia', 'paradisematic', 'country', 'roasted', 'parts', 'sentences', 'fly', 'mouth', 'even', 'all-powerful', 'pointing', 'control', 'blind', 'texts', 'almost', 'unorthographic', 'life', 'one', 'day', 'however'] \n",
      "\n",
      "109 \n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
      "\n",
      "95 \n",
      " {'far': 4, 'away': 1, 'behind': 1, 'word': 1, 'mountains': 2, 'countries': 1, 'vokalia': 1, 'consonantia': 1, 'live': 2, 'blind': 4, 'texts': 2, 'separated': 1, 'bookmarksgrove': 2, 'right': 1, 'coast': 1, 'semantics': 1, 'large': 1, 'language': 1, 'ocean': 1, 'small': 2, 'river': 1, 'named': 1, 'duden': 1, 'flows': 1, 'place': 1, 'supplies': 1, 'necessary': 1, 'regelialia': 1, 'paradisematic': 1, 'country': 1, 'roasted': 1, 'parts': 1, 'sentences': 1, 'fly': 1, 'mouth': 1, 'even': 1, 'all-powerful': 1, 'pointing': 1, 'control': 1, 'almost': 1, 'unorthographic': 1, 'life': 1, 'one': 1, 'day': 1, 'however': 1, 'line': 2, 'text': 2, 'name': 1, 'lorem': 1, 'ipsum': 1, 'decided': 1, 'leave': 1, 'world': 1, 'grammar': 1, 'big': 1, 'oxmox': 1, 'advised': 1, 'thousands': 1, 'bad': 1, 'commas': 1, 'wild': 1, 'question': 2, 'marks': 1, 'devious': 1, 'semikoli': 1, 'little': 1, '’': 1, 'listen': 1, 'packed': 1, 'seven': 1, 'versalia': 1, 'put': 1, 'initial': 1, 'belt': 1, 'made': 1, 'way': 1, 'reached': 1, 'first': 1, 'hills': 1, 'italic': 1, 'last': 1, 'view': 1, 'back': 1, 'skyline': 1, 'hometown': 1, 'headline': 1, 'alphabet': 1, 'village': 1, 'subline': 1, 'road': 1, 'lane': 1, 'pityful': 1, 'rethoric': 1, 'ran': 1, 'cheek': 1}\n"
     ]
    }
   ],
   "source": [
    "# apply lowercase and stopwords\n",
    "\n",
    "eng_stopwords = set(stopwords.words('english') + [\".\", \",\", \"?\", \"!\"])\n",
    "print(\"lenth of stopwords: \", len(eng_stopwords), \"\\n\")\n",
    "\n",
    "tokens = []\n",
    "targets = []\n",
    "for doc, tgt in zip(arr, df['target']):\n",
    "    doc = doc.lower()\n",
    "    token = word_tokenize(doc)\n",
    "    token = [tk for tk in token if tk not in eng_stopwords]\n",
    "    for _ in range(len(token)):\n",
    "        targets.append(tgt)\n",
    "    tokens += token\n",
    "    \n",
    "print(len(tokens), \"\\n\", tokens[:50], \"\\n\")\n",
    "print(len(targets), \"\\n\", targets[:50], \"\\n\")\n",
    "\n",
    "# counts\n",
    "counts = Counter(tokens)\n",
    "print(len(counts), \"\\n\", dict(counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
